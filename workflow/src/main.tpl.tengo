wf := import("@platforma-sdk/workflow-tengo:workflow")
assets:= import("@platforma-sdk/workflow-tengo:assets")
render := import("@platforma-sdk/workflow-tengo:render")
xsv := import("@platforma-sdk/workflow-tengo:pframes.xsv")
pframes := import("@platforma-sdk/workflow-tengo:pframes")
pSpec := import("@platforma-sdk/workflow-tengo:pframes.spec")

pfUMAPConv := import(":pf-umap-conv")
pfTSNEConv := import(":pf-tsne-conv")
pfPCAConv := import(":pf-pca-conv")

pfUMAPBatchConv := import(":pf-umap-batch-conv")
pfTSNEBatchConv := import(":pf-tsne-batch-conv")
pfPCABatchConv := import(":pf-pca-batch-conv")
// pfRawCountsConv := import(":pf-counts-conv")
// pfNormCountsConv := import(":pf-norm-counts-conv")

dimReductionTpl := assets.importTemplate(":dim-reduction-calculation")
batchCorrectionTpl := assets.importTemplate(":batch-correction")

wf.prepare(func(args){
	metaRefs := {}
	i := 0

	for metaRef in args.covariateRefs {
		metaRefs["metaRef" + i ] = wf.resolve(metaRef, { errIfMissing: true })
		i = i + 1
	}

	return {
		resolvedInput: wf.resolve(args.countsRef, { errIfMissing: true }),
		metaRefs: metaRefs 
	}
})

wf.body(func(args) {

	blockId := wf.blockId().getDataAsJson()
	rawCounts := args.resolvedInput
	inputSpec := rawCounts.spec

	nPCs := args.nPCs
	nNeighbors := args.nNeighbors
	hvgCount := 0
	if args.hvgEnabled {
		hvgCount = args.hvgCount
	}

	// Set default memory and CPU for imports
    defaultConvMem := "16GiB" // @TODO: set based on the size of the input
    defaultConvCpu := 1 // @TODO: set based on the size of the input

	csvCounts := xsv.exportFrame([rawCounts], "csv", { mem: defaultConvMem, cpu: defaultConvCpu })

	// Always run regular dimensionality reduction
	dimReductionRender := render.create(dimReductionTpl, {
		csvCounts: csvCounts,
		nPCs: nPCs,
		nNeighbors: nNeighbors,
		hvgCount: hvgCount,
		mem: "32GiB",
		cpu: 16
	})

	UMAPDimImportParams := pfUMAPConv.getColumns(blockId, inputSpec)
	UMAPPf := xsv.importFile(dimReductionRender.output("umapResultsCsv"), "csv", UMAPDimImportParams, {splitDataAndSpec: true, mem: defaultConvMem, cpu: defaultConvCpu})

	tSNEDimImportParams := pfTSNEConv.getColumns(blockId, inputSpec)
	tSNEPf := xsv.importFile(dimReductionRender.output("tsneResultsCsv"), "csv", tSNEDimImportParams, {splitDataAndSpec: true, mem: defaultConvMem, cpu: defaultConvCpu})

	PCADimImportParams := pfPCAConv.getColumns(blockId, inputSpec)
	PCAPf := xsv.importFile(dimReductionRender.output("pcaResultsCsv"), "csv", PCADimImportParams, {splitDataAndSpec: true, mem: defaultConvMem, cpu: defaultConvCpu})

	// Conditionally run batch correction if covariates are provided
	UMAPHarmonyPf := undefined
	tSNEHarmonyPf := undefined
	PCAHarmonyPf := undefined
	
	if len(args.covariateRefs) > 0 {
		covariates := []
		for _, v in args.metaRefs {
			covariates = append(covariates, v)
		}
		
		csvCovariates := xsv.exportFrame(covariates, "csv", {})

		batchCorrectionRender := render.create(batchCorrectionTpl, {
			csvCounts: csvCounts,
			csvCovariates: csvCovariates,
			hvgCount: hvgCount,
			mem: "32GiB",
			cpu: 16
		})

    	// Process harmony-corrected results
    	UMAPHarmonyDimImportParams := pfUMAPBatchConv.getColumns(blockId, inputSpec)
    	UMAPHarmonyPf = xsv.importFile(batchCorrectionRender.output("umapDimensionsCsv"), "csv", UMAPHarmonyDimImportParams, {splitDataAndSpec: true, mem: defaultConvMem, cpu: defaultConvCpu})

    	tSNEHarmonyDimImportParams := pfTSNEBatchConv.getColumns(blockId, inputSpec)
    	tSNEHarmonyPf = xsv.importFile(batchCorrectionRender.output("tsneDimensionsCsv"), "csv", tSNEHarmonyDimImportParams, {splitDataAndSpec: true, mem: defaultConvMem, cpu: defaultConvCpu})

		// batchCorrectedCountsImportParams := pfRawCountsConv.getColumns(blockId, inputSpec, species)
		// batchCorrectedCountsPf := xsv.importFile(batchCorrection.getFile("batch_corrected_counts.csv"), "csv", batchCorrectedCountsImportParams)

    	PCAHarmonyDimImportParams := pfPCABatchConv.getColumns(blockId, inputSpec)
    	PCAHarmonyPf = xsv.importFile(batchCorrectionRender.output("harmonyResultsCsv"), "csv", PCAHarmonyDimImportParams, {splitDataAndSpec: true, mem: defaultConvMem, cpu: defaultConvCpu})

		// batchCorrectedNormalizedCountsImportParams := pfNormCountsConv.getColumns(blockId, inputSpec, species)
		// batchCorrectedNormalizedCountsPf := xsv.importFile(batchCorrection.getFile("batch_corrected_normalized_counts.csv"), "csv", batchCorrectedNormalizedCountsImportParams)
	}

	// Make trace with informative label
	traceLabel := "Dimensionality Reduction (nPCs:" + string(nPCs) + ", nNeighbors:" + string(nNeighbors) + ")"

	// Make trace
	trace := pSpec.makeTrace(inputSpec,
		{
			type: "milaboratories.dimensionality-reduction", 
			id: blockId, importance: 35, 
			label: traceLabel
		}
	)
	// Make batch correction trace
	trace_batch := pSpec.makeTrace(inputSpec,
		{
			type: "milaboratories.dimensionality-reduction", 
			id: blockId, importance: 35, 
			label: "Batch Corrected " + traceLabel
		}
	)

	//////////// Outputs ////////////

	// Build UMAP pFrame for outputs
	umapOutputPf := pframes.pFrameBuilder()
	for k, v in UMAPPf {
		umapOutputPf.add(k, trace.inject(v.spec), v.data)
	}
	umapOutputPf = umapOutputPf.build()

	// Build tSNE pFrame for outputs
	tsneOutputPf := pframes.pFrameBuilder()
	for k, v in tSNEPf {
		tsneOutputPf.add(k, trace.inject(v.spec), v.data)
	}
	tsneOutputPf = tsneOutputPf.build()

	// Build outputs pFrame
	outputs := {
		UMAPPf: pframes.exportFrame(umapOutputPf),
		tSNEPf: pframes.exportFrame(tsneOutputPf)
	}

	// Conditionally build harmony-corrected outputs pFrame
	if len(args.covariateRefs) > 0 {
		umapHarmonyOutputPf := pframes.pFrameBuilder()
		for k, v in UMAPHarmonyPf {
			umapHarmonyOutputPf.add(k, trace_batch.inject(v.spec), v.data)
		}
		umapHarmonyOutputPf = umapHarmonyOutputPf.build()

		tsneHarmonyOutputPf := pframes.pFrameBuilder()
		for k, v in tSNEHarmonyPf {
			tsneHarmonyOutputPf.add(k, trace_batch.inject(v.spec), v.data)
		}
		tsneHarmonyOutputPf = tsneHarmonyOutputPf.build()

		outputs.UMAPHarmonyPf = pframes.exportFrame(umapHarmonyOutputPf)
		outputs.tSNEHarmonyPf = pframes.exportFrame(tsneHarmonyOutputPf)
	}

	//////////// Exports ////////////

	// Build combined exports pFrame
	exportsPf := pframes.pFrameBuilder()
	i := 0
	
	for pf in [UMAPPf, tSNEPf, PCAPf] {
		for k, v in pf {
			exportsPf.add(string(i) + "_" + k, trace.inject(v.spec), v.data)
			i = i + 1
		}
	}
	
	// Conditionally add harmony-corrected outputs to exports pFrame
	if len(args.covariateRefs) > 0 {
		for pf in [UMAPHarmonyPf, tSNEHarmonyPf] {
			for k, v in pf {
				exportsPf.add(string(i) + "_" + k, trace_batch.inject(v.spec), v.data)
				i = i + 1
			}
		}
	}

	exportsPf = exportsPf.build()

	return {
		outputs: outputs,
		exports: {
			pf: exportsPf
		}
	}
})

